version: '3'
services:
  mongo:
    image: mongo
    container_name: mongodb
    hostname: mongodb
    restart: always
    expose:
      - "6016" 
    ports:
      - "27017:27017"
    volumes:
      - ./mongodb_data:/data/db

  adminmongo:
    image: mrvautin/adminmongo
    container_name: adminmongo
    hostname: adminmongo
    ports:
      - "1234:1234"
    environment:
      - HOST=0.0.0.0

  jupyter:
    build:
      context: ./dockerfile
      dockerfile: dockerfile-jupyter
    container_name: jupyter
    hostname: jupyter
    restart: unless-stopped
    ports:
      - "5000:5000"
      - "8888:8888"
    command: start-notebook.sh --NotebookApp.token=''
    volumes:
      - ./jupyter_data:/home/jovyan/work
  
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    container_name: hadoop-namenode
    restart: always
    ports:
      - 50070:50070
      - 9000:9000
    volumes:
      - ./hadoop_conf/hadoop_namenode:/hadoop/dfs/name
      - ./hadoop_data:/user_data
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop_env/hadoop.env

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: hadoop-datanode
    restart: always
    volumes:
      - ./hadoop_conf/hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    env_file:
      - ./hadoop_env/hadoop.env
  
  spark-master:
    image: gettyimages/spark
    container_name: spark-master
    hostname: master
    expose:
      - 7001
      - 7002
      - 7003
      - 7004
      - 7005
      - 7077
      - 6066    
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 8080:8080    
    command: bin/spark-class org.apache.spark.deploy.master.Master -h master
    volumes:
      - ./spark_conf/master:/conf
      - ./spark_data:/tmp/data    
    environment:
      - MASTER: spark://master:7077
      - SPARK_CONF_DIR: /conf
      - SPARK_PUBLIC_DNS: localhost
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      
  spark-worker:
    image: gettyimages/spark
    container_name: spark-worker
    hostname: worker
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 8881
    ports:
      - 8081:8081
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077
    volumes:
      - ./spark_conf/worker:/conf
      - ./spark_data:/tmp/data
    environment:
      - SPARK_CONF_DIR: /conf
      - SPARK_WORKER_CORES: 2
      - SPARK_WORKER_MEMORY: 1g
      - SPARK_WORKER_PORT: 8881
      - SPARK_WORKER_WEBUI_PORT: 8081
      - SPARK_PUBLIC_DNS: localhost
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    links:
      - master
      
  zookeeper:
    image: confluentinc/cp-zookeeper:5.2.1
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:5.2.1
    container_name: kafka
    hostname: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      
  restproxy:
    image: confluentinc/cp-kafka-rest:5.2.1
    container_name: restproxy
    hostname: restproxy
    depends_on:
      - kafka
    restart: always
    ports:
      - 8082:8082
    environment:
      KAFKA_REST_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_REST_LISTENERS: http://0.0.0.0:8082
      KAFKA_REST_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KAFKA_REST_HOST_NAME: restproxy
      KAFKA_REST_DEBUG: "true"

  ksql-server:
    image: confluentinc/cp-ksql-server
    container_name: ksql-server
    depends_on:
      - kafka
    ports:
      - "8089:8089"
    environment:
      KSQL_BOOTSTRAP_SERVERS: kafka:9092
      KSQL_LISTENERS: "http://0.0.0.0:8089"
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8083"
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_CONFIG_DIR: "/etc/ksql"
      KSQL_LOG4J_OPTS: "-Dlog4j.configuration=file:/etc/ksql/log4j-rolling.properties"

  ksql-cli:
    image: confluentinc/cp-ksql-cli
    container_name: ksql-cli
    depends_on:
      - kafka
      - ksql-server
    entrypoint: /bin/sh
    tty: true

  schema-registry:
    image: confluentinc/cp-schema-registry:5.2.1
    container_name: schema-registry
    depends_on:
      - kafka
      - zookeeper
    ports:
      - "8083:8083"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper:2181'
