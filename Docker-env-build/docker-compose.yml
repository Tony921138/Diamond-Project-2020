version: '3'
services:
  mongo:
    image: mongo
    container_name: mongodb
    hostname: mongodb
    restart: always
    expose:
      - "6016" 
    ports:
      - "27017:27017"
    volumes:
      - ./mongodb:/data/db

  adminmongo:
    image: mrvautin/adminmongo
    container_name: adminmongo
    hostname: adminmongo
    ports:
      - "1234:1234"
    environment:
      - HOST=0.0.0.0

  jupyter:
    build:
      context: ./dockerfile
      dockerfile: dockerfile-jupyter
    container_name: jupyter
    hostname: jupyter
    restart: unless-stopped
    ports:
      - "5000:5000"
      - "8888:8888"
    command: start-notebook.sh --NotebookApp.token=''
    volumes:
      - ./jupyter:/home/jovyan/work
  
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    container_name: hadoop-namenode
    restart: always
    ports:
      - 50070:50070
      - 9000:9000
    volumes:
      - ./hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: hadoop-datanode
    restart: always
    volumes:
      - ./hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    env_file:
      - ./hadoop.env
  
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop2.7.4-java8
    container_name: yarn-resourcemanager
    restart: always
    ports:
      - 8088:8088
    environment:
      SERVICE_PRECONDITION: "namenode:50070 namenode:9000 datanode:50075"
    env_file:
      - ./hadoop.env

  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop2.7.4-java8
    container_name: yarn-nodemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:50070 namenode:9000 datanode:50075 resourcemanager:8088"
    env_file:
      - ./hadoop.env
  
  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop2.7.4-java8
    container_name: yarn-historyserver
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:50070 namenode:9000 datanode:50075 resourcemanager:8088"
    volumes:
      - ./hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env
  
  spark-master:
    image: bde2020/spark-master:2.4.5-hadoop2.7
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    depends_on:
      - namenode
      - datanode
    command: >
      sh -c "export PYSPARK_PYTHON=/usr/bin/python3.7 && 
             export PYSPARK_DRIVER_PYTHON=/usr/bin/python3.7"
    tty: true
      
  spark-worker-1:
    image: bde2020/spark-worker:2.4.5-hadoop2.7
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    command: >
      sh -c "export PYSPARK_PYTHON=/usr/bin/python3.7 && 
             export PYSPARK_DRIVER_PYTHON=/usr/bin/python3.7"
    tty: true
             
  spark-worker-2:
    image: bde2020/spark-worker:2.4.5-hadoop2.7
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8084:8084"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    command: >
      sh -c "export PYSPARK_PYTHON=/usr/bin/python3.7 && 
             export PYSPARK_DRIVER_PYTHON=/usr/bin/python3.7"
    tty: true
    
  zookeeper:
    image: confluentinc/cp-zookeeper:5.2.1
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:5.2.1
    container_name: kafka
    hostname: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      
  restproxy:
    image: confluentinc/cp-kafka-rest:5.2.1
    container_name: restproxy
    hostname: restproxy
    depends_on:
      - kafka
    restart: always
    ports:
      - 8082:8082
    environment:
      KAFKA_REST_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_REST_LISTENERS: http://0.0.0.0:8082
      KAFKA_REST_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KAFKA_REST_HOST_NAME: restproxy
      KAFKA_REST_DEBUG: "true"

  ksql-server:
    image: confluentinc/cp-ksql-server
    container_name: ksql-server
    depends_on:
      - kafka
    ports:
      - "8089:8089"
    environment:
      KSQL_BOOTSTRAP_SERVERS: kafka:9092
      KSQL_LISTENERS: "http://0.0.0.0:8089"
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8083"
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_CONFIG_DIR: "/etc/ksql"
      KSQL_LOG4J_OPTS: "-Dlog4j.configuration=file:/etc/ksql/log4j-rolling.properties"

  ksql-cli:
    image: confluentinc/cp-ksql-cli
    container_name: ksql-cli
    depends_on:
      - kafka
      - ksql-server
    entrypoint: /bin/sh
    tty: true

  schema-registry:
    image: confluentinc/cp-schema-registry:5.2.1
    container_name: schema-registry
    depends_on:
      - kafka
      - zookeeper
    ports:
      - "8083:8083"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper:2181'
